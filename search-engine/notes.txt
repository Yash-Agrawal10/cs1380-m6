IDEA FOUR: Combined map-reduce

Idea:
    Use map-reduce only for indexing
    Completely separate crawler, indexer, Queryer

Crawler:
    One manager node manages urlList and visitedList
        Has a function getURLs that verifies URL is not seen
        Has a function putURLs that appends to URLs
        Could maintain lists in memory, but write persistently for fault tolerance
    Many nodes actually crawl
        Use getURL to collect URLs from crawl manager
        Downloads content
        Saves text on index group
        Extracts URLs and appends them to crawl manager and index manager

Indexer:
    One manager node manages toIndex list
        Initializes map-reduce computation on worker group
    Many nodes actually index
        Map - consume (and delete) downloaded text, emit {term: url, freq}
        Reduce - append list of {url, freq} to global index distributed over queryers and sort it

Queryer:
    Many nodes store global index
    When queried, simply get global index and return top results



Details:

    Crawler:
        Orchestrator -- 
            1. Define groups for itself
            2. 